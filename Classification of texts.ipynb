{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivery 2. Classification of texts. \n",
    "---\n",
    "\n",
    "by Jaime de Cecilio \n",
    "\n",
    "\n",
    "#### Objective\n",
    "The objective of this practice is to perform a classification of a series of tweets, which are collected in the file tweets.txt. This file contains several columns separated by the symbol \":\", but we can consider that it has a CSV structure and that the separator between columns is \"::::\". In these circumstances, the first column contains the text itself, while the last one contains the label: positive, negative, neutral or None.\n",
    "\n",
    "#### Activity script\n",
    "1. Read the content of the txt file into a Data Frame. It is suggested to use the pandas.read_csv function.\n",
    "2. Perform the pre-processing that you consider necessary. You can use functions from the NLTK or spaCy library, as you wish. We recommend a modular writing of the code, to be able to test later, seeing if better results are obtained when using stop-words, when performing an extraction of canonical forms, etc.\n",
    "3. Divide the document set into a training subset and an evaluation subset.\n",
    "4. Convert the document corpus into a TF-idf matrix. It is most convenient to use the Tfidf Vectorizer, which is part of sklearn. Does the maximum number of features to be used influence the final result?\n",
    "5. At this point, perform training models at least with Naive Bayesian classifier algorithms and SVM machines. Obtain classification accuracy results as well as confusion matrices for both models.\n",
    "6. Comment on the results obtained, what factors are involved, are the results obtained as initially expected, and what is the reason for these results? Think about the quality of the data set you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importación de librerías\n",
    "\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salgo de #VeoTV , que día más largoooooo...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0        Salgo de #VeoTV , que día más largoooooo...      None\n",
       "1  @PauladeLasHeras No te libraras de ayudar me/n...    neutro\n",
       "2                          @marodriguezb Gracias MAR  positivo\n",
       "3  Off pensando en el regalito Sinde, la que se v...  negativo\n",
       "4  Conozco a alguien q es adicto al drama! Ja ja ...  positivo"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lectura de datos\n",
    "\n",
    "tweets = pd.read_csv(\"/Users/jaime2/Desktop/DATA SCIENCE/5. ANALISIS DE INFORMACION NO ESTRUCTURADA/ENTREGAS/ENTREGA 2/tweets.txt\", sep=\"::::\", encoding=\"utf-8\", header=None)\n",
    "tweets.columns = [\"text\", \"label\"]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positivo     2883\n",
       "negativo     2182\n",
       "None         1482\n",
       "neutro        670\n",
       ":positivo       1\n",
       ":negativo       1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cuántos ejemplos hay de cada tipo\n",
    "\n",
    "tweets[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positivo    2884\n",
       "negativo    2183\n",
       "None        1482\n",
       "neutro       670\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapeamos :negativo a negativo, y :positivo a positivo\n",
    "\n",
    "print(type(tweets[\"label\"]))\n",
    "\n",
    "tweets[\"label\"].replace(to_replace=[\":positivo\", \":negativo\"],value=[\"positivo\",\"negativo\"], inplace=True)\n",
    "tweets[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Eliminamos los elementos sin categoría?\n",
    "\n",
    "# tweets.drop(tweets[tweets.label==\"None\"].index, inplace=True)\n",
    "# tweets[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separaciónde documentos y de catgegorías\n",
    "\n",
    "docs = tweets.iloc[:,0] # extract column with review\n",
    "categs = tweets.iloc[:,-1] # extract column with sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de la matriz Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7219x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 51257 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizamos los documentos y convertimos en matriz TfIdf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=200)\n",
    "# vectorizer = TfidfVectorizer(max_features=200, lowercase=True, strip_accents=\"ascii\", stop_words = stopwords)\n",
    "\n",
    "docs_tfidf = vectorizer.fit_transform(docs)\n",
    "docs_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los subconjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División mediante train_test_split. Test de 25%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, categs_train, categs_test = train_test_split(docs_tfidf, categs, test_size = 0.25, \n",
    "                                                                    random_state = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador ingenuo bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento del clasificador NB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(docs_train, categs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento del clasificador NB\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "# svm = SVC(kernel='poly')\n",
    "# svm = SVC(kernel='rbf')\n",
    "# svm = SVC(kernel='sigmoid')\n",
    "\n",
    "\n",
    "svm.fit(docs_train, categs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo ingenuo bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del set de test\n",
    "\n",
    "categs_pred = clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 91,  82,   0, 176],\n",
       "       [ 29, 340,   0, 175],\n",
       "       [  4,  92,   0,  72],\n",
       "       [ 52, 153,   0, 539]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(categs_test, categs_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy entrenamiento:  0.5615072035463613\n",
      "Accuracy PRUEBA:  0.5373961218836565\n",
      "Fiabilidad:  0.9570600670651698\n"
     ]
    }
   ],
   "source": [
    "acc_train = clf.score(docs_train, categs_train)\n",
    "acc_test = clf.score(docs_test, categs_test)\n",
    "\n",
    "print(\"Accuracy entrenamiento: \", acc_train)\n",
    "print(\"Accuracy PRUEBA: \", acc_test)\n",
    "print(\"Fiabilidad: \", acc_test / acc_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del set de test\n",
    "\n",
    "categs_pred = svm.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142,  73,   0, 134],\n",
       "       [ 54, 345,   1, 144],\n",
       "       [ 11,  99,   0,  58],\n",
       "       [ 98, 168,   0, 478]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(categs_test, categs_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy entrenamiento:  0.583671961581086\n",
      "Accuracy PRUEBA:  0.5346260387811634\n",
      "Fiabilidad:  0.9159700550510187\n"
     ]
    }
   ],
   "source": [
    "acc_train = svm.score(docs_train, categs_train)\n",
    "acc_test = svm.score(docs_test, categs_test)\n",
    "\n",
    "print(\"Accuracy entrenamiento: \", acc_train)\n",
    "print(\"Accuracy PRUEBA: \", acc_test)\n",
    "print(\"Fiabilidad: \", acc_test / acc_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.84136400000001,
   "position": {
    "height": "222.841px",
    "left": "730.622px",
    "right": "20px",
    "top": "7.99999px",
    "width": "310px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
